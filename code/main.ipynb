{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Libraries\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "from torchvision import transforms\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setting generic hyperparameters\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "num_epochs: int = 3#20\n",
    "batch_size: int = 250   # Should be set to a power of 2.\n",
    "# Learning rate\n",
    "lr:         float = 0.002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Data Preprocessing\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#TODO Preprocess the AILARON dataset to a suitable format.\n",
    "\n",
    "# #TODO Implement custome dataset for AILARON data. Should inherit from torch.utils.data.Dataset\n",
    "# class AILARONDataset(torchvision.Dataset):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         # Load data\n",
    "#         pass\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # TODO\n",
    "#         pass\n",
    "#     def __len__(self):\n",
    "#         # TODO\n",
    "#         pass \n",
    "\n",
    "# ailaron_train = AILARONDataset()\n",
    "# dataloader = DataLoader(dataset=ailaron_train, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Load MNIST dataset, normalizes data and transform to tensor.\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "mnist_test  = torchvision.datasets.MNIST(root='./data', train=False, download=False, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "\n",
    "# # Create a subset of the MNIST dataset with the first 100 examples\n",
    "# mnist_train_subset = torch.utils.data.Subset(mnist_train, range(3000))\n",
    "# mnist_test_subset  = torch.utils.data.Subset(mnist_test, range(32))\n",
    "\n",
    "# Get a random image from the dataset\n",
    "# image, label = mnist_train[np.random.randint(0, len(mnist_train))]\n",
    "\n",
    "# # Plot the image\n",
    "# plt.imshow(image[0], cmap='gray')\n",
    "# plt.title(f'Label: {label}')\n",
    "# plt.show()\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preprocessing Data\n",
    "\"\"\"\n",
    "\n",
    "# define data augmentation transforms\n",
    "transform_aug = transforms.Compose([\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.ColorJitter(brightness=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1/255,))      # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# define the transformation to be applied on the original dataset\n",
    "transform_orig = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1/255,))      # Normalize to range [-1, 1]\n",
    "])\n",
    "\n",
    "# load the MNIST dataset\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "\n",
    "mnist_train_aug = [((transform_orig(image), transform_aug(image)), label) for image, label in mnist_train]\n",
    "\n",
    "# create a data loader for the combined dataset\n",
    "trainloader = torch.utils.data.DataLoader(mnist_train_aug, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size:  60000\n",
      "Batch size:  250\n",
      "Number of batches:  240\n",
      "Data shape:  torch.Size([1, 28, 28])\n",
      "Batch 1:\n",
      "Labels: tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Exploring code\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# for _, data in enumerate(test_loader):\n",
    "#     # Get the inputs and true labels for the mini-batch and reshape\n",
    "#     inputs, labels_true = data\n",
    "\n",
    "\n",
    "# Get the dataset\n",
    "dataset = trainloader.dataset\n",
    "\n",
    "# Get the size of the dataset\n",
    "dataset_size = len(dataset)\n",
    "\n",
    "# Get the batch size\n",
    "batch_size = trainloader.batch_size\n",
    "\n",
    "# Get the number of batches\n",
    "num_batches = len(trainloader)\n",
    "\n",
    "# Get the shape of the data\n",
    "data_shape = next(iter(trainloader))[0].shape[1:]\n",
    "\n",
    "# Print the attributes\n",
    "print(\"Dataset size: \", dataset_size)\n",
    "print(\"Batch size: \", batch_size)\n",
    "print(\"Number of batches: \", num_batches)\n",
    "print(\"Data shape: \", data_shape)\n",
    "\n",
    "\n",
    "for batch_idx, (images, labels, augmented_images) in enumerate(trainloader):\n",
    "    # access the label, image and augmented image for each batch\n",
    "    print(f'Batch {batch_idx+1}:')\n",
    "    print('Labels:', labels[0])\n",
    "    # print('Original images:', images)\n",
    "    # print('Augmented images:', augmented_images)\n",
    "\n",
    "    # Plot the image\n",
    "    plt.imshow(augmented_images[0][0], cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    # plt.imshow(augmented_images[0], cmap='gray')\n",
    "    # plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unsupervised Machine Learning Framework\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def train(model, train_loader: DataLoader, criterion: Callable, optimizer: torch.optim, num_epochs: int) -> None:\n",
    "    \"\"\"\n",
    "    Trains a given model using the provided training data, optimizer and loss criterion for a given number of epochs.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network model to train.\n",
    "        train_loader: PyTorch data loader containing the training data.\n",
    "        criterion: Loss criterion used for training the model.\n",
    "        optimizer: Optimizer used to update the model's parameters.\n",
    "        num_epochs: Number of epochs to train the model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Loop over the epochs\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Initialize running loss for the epoch\n",
    "        running_loss = 0.0\n",
    "        running_acc  = 0.0\n",
    "\n",
    "        # Loop over the mini-batches in the data loader\n",
    "        for _, data in enumerate(train_loader):\n",
    "        \n",
    "            # Get the inputs and labels for the mini-batch and reshape\n",
    "            inputs, labels = data\n",
    "            inputs         = inputs.view(-1, 28*28)\n",
    "        \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "            # Forward pass through the model\n",
    "            outputs = F.softmax(model(inputs), dim=1)\n",
    "        \n",
    "            # Compute the loss\n",
    "            loss = criterion(model, inputs, outputs)\n",
    "            # Backward pass through the model and compute gradients\n",
    "            loss.backward()\n",
    "        \n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the loss for the mini-batch\n",
    "            running_loss += loss.item()\n",
    "            # Accumulate the accuracy for the mini-batch\n",
    "            running_acc  += unsupervised_clustering_accuracy(labels, torch.argmax(outputs, dim=1))\n",
    "\n",
    "        # Compute the average loss for the epoch and print\n",
    "        print(f\"Epoch {epoch+1} loss: {running_loss/len(train_loader):.4f}, ACC: {running_acc/len(train_loader):.4f}\")\n",
    "\n",
    "\n",
    "def unsupervised_clustering_accuracy(y_true: torch.Tensor, y_pred: torch.Tensor) -> float:\n",
    "    \"\"\"\n",
    "    Computes the unsupervised clustering accuracy between two clusterings.\n",
    "    Uses the Hungarian algorithm to find the best matching between true and predicted labels.\n",
    "\n",
    "    Args:\n",
    "        y_true: true cluster labels as a 1D torch.Tensor\n",
    "        y_pred: predicted cluster labels as a 1D torch.Tensor\n",
    "\n",
    "    Returns:\n",
    "        accuracy: unsupervised clustering accuracy as a float\n",
    "    \"\"\"\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_pred, y_true)\n",
    "\n",
    "    # Compute best matching between true and predicted labels using the Hungarian algorithm\n",
    "    _, col_ind = linear_sum_assignment(-cm)\n",
    "\n",
    "    # Reassign labels for the predicted clusters\n",
    "    y_pred_reassigned = torch.tensor(col_ind)[y_pred.long()]\n",
    "\n",
    "    # Compute accuracy as the percentage of correctly classified samples\n",
    "    acc = accuracy_score(y_true, y_pred_reassigned)\n",
    "\n",
    "    return acc\n",
    "\n",
    "\n",
    "def test_classifier(model, test_loader: DataLoader) -> None:\n",
    "    \"\"\"\n",
    "    Testing a classifier given the model and a test set.\n",
    "\n",
    "    Args:\n",
    "        model: Neural network model to train.\n",
    "        test_loader: PyTorch data loader containing the test data.\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    # Disable gradient computation, as we don't need it for inference\n",
    "    model.eval()\n",
    "    # Initialize tensors for true and predicted labels\n",
    "    y_true = torch.zeros(len(test_loader.dataset))\n",
    "    y_pred = torch.empty(len(test_loader.dataset))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Iterate over the mini-batches in the data loader\n",
    "        for i, data in enumerate(test_loader):\n",
    "            # Get the inputs and true labels for the mini-batch and reshape\n",
    "            inputs, labels_true = data\n",
    "            inputs = inputs.view(-1, 28*28)\n",
    "\n",
    "            # Forward pass through the model to get predicted labels\n",
    "            labels_pred = F.softmax(model(inputs), dim=1)\n",
    "\n",
    "            # Store predicted and true labels in tensors\n",
    "            y_pred[i*len(labels_true):(i+1)*len(labels_true)] = torch.argmax(labels_pred, dim=1)\n",
    "            y_true[i*len(labels_true):(i+1)*len(labels_true)] = labels_true\n",
    "\n",
    "    # Compute unsupervised clustering accuracy score\n",
    "    acc = unsupervised_clustering_accuracy(y_true, y_pred)\n",
    "\n",
    "    print(f\"\\nThe unsupervised clustering accuracy score of the classifier is: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unsupervised Machine Learning Algorithms\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#TODO Consider implementing models as classes.\n",
    "\n",
    "from archt import NeuralNet\n",
    "\n",
    "# Information Maximizing Self-Augmented Training\n",
    "from IMSAT import regularized_information_maximization\n",
    "\n",
    "# Invariant Information Clustering\n",
    "from IIC import invariant_information_clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 loss: -1.0324, ACC: 0.2596\n",
      "Epoch 2 loss: -1.4713, ACC: 0.2673\n",
      "Epoch 3 loss: -1.4714, ACC: 0.2648\n",
      "\n",
      "The unsupervised clustering accuracy score of the classifier is: 0.2454\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model     = NeuralNet()\n",
    "criterion = invariant_information_clustering\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Train the model\n",
    "train(model, train_loader, criterion, optimizer, num_epochs)\n",
    "# Test model\n",
    "test_classifier(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
